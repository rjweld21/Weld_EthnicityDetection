{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "from time import sleep\n",
    "from math import ceil\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Functions for data cleaning/organizing which are then called in next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_image_paths(imagePath):\n",
    "    # Joins image filenames with rest of whole path\n",
    "    paths = []\n",
    "    for oneImage in os.listdir(imagePath):\n",
    "        paths.append(os.path.join(imagePath, oneImage))\n",
    "        \n",
    "    shuffle(paths) # Shuffles list then returns\n",
    "    return paths\n",
    "\n",
    "def remove_some_eth(df, label, reduce, poss_labels):\n",
    "    # Removes some examples from specified eth to try and match up category example sizes\n",
    "    \n",
    "    # Gets base DF, all rows not including labels to reduce\n",
    "    base = df[df['ethnicity'] != label].reset_index(drop=True)\n",
    "    \n",
    "    # Gets rows including labels to reduce then reduces it\n",
    "    eth_to_drop = df[df['ethnicity'] == label]\n",
    "    eth = eth_to_drop.sample(frac=reduce).reset_index(drop=True)\n",
    "    \n",
    "    # Concats reduced labels with all other labels split previously\n",
    "    new_df = pd.concat([base, eth]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Outputs new label counts\n",
    "    print('Ethnicity %s reduced... new counts...' % label)\n",
    "    for l in sorted(set(new_df['ethnicity'].tolist())):\n",
    "        print('%s: %s' % (l, new_df[new_df['ethnicity']==l].shape[0]))\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "def replace_image_names(paths, DF):\n",
    "    # Data cleaning... alters image names for more standardized format\n",
    "    \n",
    "    # Creates new DF for standardized image paths and ethnicities\n",
    "    print('Replacing filenames in DF with full paths')\n",
    "    new_df = pd.DataFrame(columns=('path', 'ethnicity'))\n",
    "    df = format_subs(DF)\n",
    "    poss_labels = sorted(set(DF['ethnicity'].tolist()))\n",
    "    \n",
    "    # Enumerates through paths getting subject number\n",
    "    for i, onePath in enumerate(paths):\n",
    "        # Tries to parse by one format type... If this fails it tries parsing by other format type\n",
    "        try:\n",
    "            int(onePath.split('_')[0].split('.')[-1])\n",
    "            fileSub = '-'.join(onePath.split('/')[-1].split('-')[2:]).split('_')[0]\n",
    "        except:\n",
    "            int(onePath.split('_')[1])\n",
    "            fileSub = '.'.join(onePath.split('/')[-1].split('_')[:2])\n",
    "            \n",
    "        # Gets ethnicity for file and loads params into new_df\n",
    "        fileEth = df[df['image']==fileSub]['ethnicity'].iloc[0]\n",
    "        new_df.loc[i] = [onePath, fileEth]\n",
    "        \n",
    "    for oneLabel in poss_labels:\n",
    "        print('%s: %s' % (oneLabel, new_df[new_df['ethnicity'] == oneLabel].shape[0]))\n",
    "        \n",
    "    print('\\n')\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def format_subs(DF):\n",
    "    DF['image'] = DF['image'].apply(lambda c: c.split('_')[0])\n",
    "    return DF\n",
    "\n",
    "def split_sets(DF, tr_path, val_path, ts_path, labels_path):\n",
    "    # Gets training, validation and testing sets\n",
    "    \n",
    "    # Splits up sets to 60/20/20 split\n",
    "    train, validate, test = np.split(DF.sample(frac=1).reset_index(drop=True), [int(0.6*len(DF)),\n",
    "                                                                               int(0.8*len(DF))])\n",
    "    \n",
    "    # Resets all indicies\n",
    "    train, validate, test = train.reset_index(drop=True), validate.reset_index(drop=True), test.reset_index(drop=True)\n",
    "    \n",
    "    # Writes data to files for later quicker loading\n",
    "    train.to_csv(tr_path, index=False)\n",
    "    validate.to_csv(val_path, index=False)\n",
    "    test.to_csv(ts_path, index=False)\n",
    "    DF.to_csv(labels_path, index=False)\n",
    "    \n",
    "    # Returns sets\n",
    "    return train, validate, test\n",
    "\n",
    "def getOneHot(arr, key):\n",
    "    print('Processing one-hot encoding...')\n",
    "    output = np.zeros((arr.shape[0], len(key)))\n",
    "    for i, elem in enumerate(arr):\n",
    "        output[i][key.index(elem)] = 1\n",
    "        \n",
    "    return output\n",
    "\n",
    "def conv_oneHot(DF):\n",
    "    DF['ethnicity'] = DF['ethnicity'].apply(lambda c: str_to_oneHot(c))\n",
    "    \n",
    "    return DF\n",
    "    \n",
    "def str_to_oneHot(string):\n",
    "    string = string.replace('[', '').replace(']', '').replace(',', '')\n",
    "    out_list = np.fromstring(string, dtype=np.float, sep=' ')\n",
    "    \n",
    "    return out_list\n",
    "\n",
    "def findImages(cropPaths, ethData):\n",
    "    pass\n",
    "\n",
    "def load_sets(imagePath='images/cropped', ethPath='ResNetData/imageData/cssff_ethLabels.csv', \n",
    "              tr_path='ResNetData/imageData/eth_train.csv', \n",
    "              val_path='ResNetData/imageData/eth_validation.csv', \n",
    "              test_path='ResNetData/imageData/eth_testing.csv', \n",
    "              labels_path='ResNetData/imageData/eth_labels.csv', proc_choice=1):\n",
    "    \n",
    "    ethData = pd.read_csv(ethPath, index_col=False)\n",
    "    poss_labels = sorted(set(ethData['ethnicity'].tolist()))\n",
    "    \n",
    "    cropPaths = join_image_paths(imagePath)\n",
    "    \n",
    "    if proc_choice==1:\n",
    "        print('Processing paths with first choice... This may take some time...')\n",
    "        ethData = remove_some_eth(replace_image_names(cropPaths, ethData), label='Caucasian', reduce=0.6,\n",
    "                                 poss_labels=classes)\n",
    "        ethData['ethnicity'] = list(getOneHot(np.array(ethData['ethnicity'].tolist()), classes))\n",
    "        \n",
    "        training_set, validation_set, testing_set = split_sets(ethData, tr_path, val_path, test_path, labels_path)\n",
    "        \n",
    "    elif proc_choice==2:\n",
    "        print('Processing paths with second choice... Loading paths from files...')\n",
    "        training_set = conv_oneHot(pd.read_csv(tr_path))\n",
    "        validation_set = conv_oneHot(pd.read_csv(val_path))\n",
    "        testing_set = conv_oneHot(pd.read_csv(test_path))\n",
    "        ethData = pd.read_csv(labels_path)\n",
    "        \n",
    "    print('\\nTraining, validation and testing sets loaded...')\n",
    "    print('Sizes:\\nTraining: %s\\nValidation: %s\\nTesting: %s' % (training_set.shape[0], validation_set.shape[0],\n",
    "                                                                testing_set.shape[0]))\n",
    "        \n",
    "    return training_set, validation_set, testing_set, ethData, poss_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep and architecture param declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image paths\n",
    "image_path = 'images/cropped'\n",
    "imagePaths = join_image_paths(image_path)\n",
    "print(len(imagePaths))\n",
    "\n",
    "# Get training, validation and testing sets. Also gets full data and de-duplicated class list\n",
    "tr_set, val_set, ts_set, eth_data, classes = load_sets(proc_choice=2)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = [224, 224, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths, size=224):\n",
    "    all_images = np.zeros((len(image_paths), size, size, 3))\n",
    "    \n",
    "    for i, _path in enumerate(image_paths):\n",
    "        # Read image\n",
    "        image = plt.imread(_path)\n",
    "        # Resize\n",
    "        img = cv2.resize(image, (size, size))\n",
    "        # Normalize\n",
    "        img = np.divide(image, [255., 255., 255.])\n",
    "        # Append\n",
    "        all_images[i] = img\n",
    "        \n",
    "    return all_images\n",
    "\n",
    "def printO(string, filename, header=True, custom_header=False, new_line=True):\n",
    "    # Function for printing updates to log incase notebook session is closed on local machine\n",
    "    \n",
    "    # If-else for clearing file or appending contents\n",
    "    if string == 'CLEARFILE':\n",
    "        f = open(filename, 'w')\n",
    "        \n",
    "        # If-else for creating header at beginning of empty log\n",
    "        if custom_header:\n",
    "            fill = custom_header\n",
    "        elif header:\n",
    "            fill = 'Training began at %s\\n\\n' % datetime.now()\n",
    "        else:\n",
    "            fill = ''\n",
    "        f.write(fill)\n",
    "        f.close()\n",
    "        print('User output file %s cleared...' % filename.split('/')[-1])\n",
    "        \n",
    "    else:\n",
    "        print(string)\n",
    "        f = open(filename, 'a')\n",
    "        if new_line:\n",
    "            string += '\\n'\n",
    "        f.write(string)\n",
    "        f.close()\n",
    "        \n",
    "def getMaxBatch(DF, max_set):\n",
    "    current_batch = pd.DataFrame(columns=list(DF))\n",
    "    DF = DF.reset_index(drop=True)\n",
    "    \n",
    "    if max_set > DF.shape[0]:\n",
    "        max_set = DF.shape[0]+1\n",
    "        \n",
    "    current_batch = DF.loc[:max_set, :]\n",
    "    \n",
    "    DF = DF.drop(DF.index[:max_set])\n",
    "    \n",
    "    return DF.reset_index(drop=True), current_batch.reset_index(drop=True)\n",
    "\n",
    "def getBatch(batchDF, image_max):\n",
    "    batchDF, current_batch = getMaxBatch(batchDF, image_max)\n",
    "            \n",
    "    X_tr = load_images(current_batch['path'].tolist())\n",
    "    Y_tr = current_batch['ethnicity'].tolist()\n",
    "    \n",
    "    return batchDF, X_tr, Y_tr\n",
    "\n",
    "def mostCommonIncorrectPred(incorrect_dict):\n",
    "    outStr = '\\n\\nActual Ethnicity: Most Common Misprediction\\n'\n",
    "    outCSV = 'ACT_LABEL,' + ','.join(classes) + '\\n'\n",
    "    for key in classes:\n",
    "        amount = []\n",
    "        outCSV += key + ','\n",
    "        for lookFor in classes:\n",
    "            amount.append(incorrect_dict[key].count(lookFor))\n",
    "            outCSV += str(amount[-1]) + ','\n",
    "            \n",
    "        outCSV += '\\n'\n",
    "        outStr += '%s: %s\\n' % (key, classes[np.argmax(amount)])\n",
    "        \n",
    "    return outStr, outCSV\n",
    "\n",
    "def postBatchProcessing(c, wholeDF, tempDF, image_max, ticker, file_to_write, stage='training'):\n",
    "    c+=1 \n",
    "    printO('%s - At iteration %s of %s for batches' % (stage, c, ceil(wholeDF.shape[0]/image_max)),\n",
    "           filename=file_to_write)\n",
    "    printO('Estimated time for this epoch\\'s %s completion: %s\\n' % (stage,\n",
    "                            ((datetime.now()-ticker)*ceil(tempDF.shape[0]/image_max))),\n",
    "           filename=file_to_write)\n",
    "    ticker = datetime.now()\n",
    "    \n",
    "    return c, ticker\n",
    "\n",
    "# Learning rate scheduler\n",
    "# lr to be reduced based on number of epochs\n",
    "def lr_schedule(epoch):\n",
    "\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 150:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 100:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 50:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# A function to build layers for the Resnet:\n",
    "    # 1. Conv\n",
    "    # 2. Batch normalization\n",
    "    # 3. Activation\n",
    "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    # Convolution operation\n",
    "    conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    x = conv(x)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "        x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_create(input_shape, depth, num_classes=10, stack_size=6):\n",
    "    \"\"\"\n",
    "    First stack does not change the size\n",
    "    Later, at the beginning of each stack, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stack 0: 224x224, 16\n",
    "    stack 1: 112x112, 32\n",
    "    stack 2:  56x56,  64\n",
    "    stack 3:  28x28,  128\n",
    "    stack 4:  14x14,  256\n",
    "    stack 5:  7x7,  512\n",
    "    GlobalAveragePooling 7x7, 512 -> 1x1, 512\n",
    "    Flatten 1x1, 512 -> 512\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(stack_size):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
    "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match changed dims\n",
    "                x = resnet_layer(inputs=x, num_filters=num_filters, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n",
    "            # Add skip connection\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2                    # Increase number of filter\n",
    "\n",
    "    # Add classifier on top.\n",
    "    x = AveragePooling2D(pool_size=7)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def getAcc(model, X_set, Y_set, incorrect_dict):\n",
    "    preds = model.predict(X_set)\n",
    "    if not incorrect_dict:\n",
    "        incorrect_dict = {key: [] for key in classes}\n",
    "        \n",
    "    correct = 0\n",
    "    for i, prediction in enumerate(preds):\n",
    "        if np.argmax(prediction) == np.argmax(Y_set[i]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            actu_eth = classes[np.argmax(Y_set[i])]\n",
    "            pred_eth = classes[np.argmax(prediction)]\n",
    "            incorrect_dict[actu_eth].append(pred_eth)\n",
    "            \n",
    "    return correct/len(preds), incorrect_dict\n",
    "\n",
    "def midTrainTest(model, X_batch, Y_batch, incorrect_dict, acc, batches, file_to_write, batchTime, \n",
    "                             stage='training'):\n",
    "    \n",
    "    a, incorrect_dict = getAcc(model, X_batch, Y_batch, incorrect_dict)\n",
    "    acc.append(a)\n",
    "    #loss.append(model.evaluate(X_batch, Y_batch, verbose=0))\n",
    "    printO(\"%s - Batch : %s\" % (stage, batches), filename=file_to_write)\n",
    "    printO(\"%s - of batch %s\" % (stage, (len(X_batch) // batch_size)), filename=file_to_write)\n",
    "    printO(\"Estimated time for %s batch completion: %s\" % (stage, ((datetime.now()-batchTime)/10)*\n",
    "                                                        ((len(X_batch)//batch_size)-batches)),\n",
    "          filename=file_to_write)\n",
    "    \n",
    "    batchTime = datetime.now()\n",
    "    \n",
    "    return acc, incorrect_dict, batchTime\n",
    "\n",
    "def updateEpochMetrics(epoch_metrics, metrics_file, acc, allAcc, loss, epoch, stage, file_to_write):\n",
    "    \n",
    "    loss = [0, 0]\n",
    "    \n",
    "    new_line = True\n",
    "    if stage == 'train':\n",
    "        new_line = False\n",
    "        print('DEBUG: ' + str(np.mean(acc)*100))\n",
    "        print('DEBUG: ' + str(len(acc)))\n",
    "        print('DEBUG: ' + str(acc))\n",
    "        met = '%s,%s,%s,' % (epoch+1, np.mean(acc)*100, np.mean(loss))\n",
    "    elif stage == 'validation':\n",
    "        met = '%s,%s' % (np.mean(acc)*100, np.mean(loss))\n",
    "    \n",
    "    epoch_metrics[stage].append([np.mean(acc)*100, np.mean(loss)])\n",
    "    printO(met, filename=metrics_file, new_line=new_line)\n",
    "    printO('%s mean of accuracy and loss for this epoch: %s' % (stage, epoch_metrics[stage][-1]),\n",
    "          filename=file_to_write)\n",
    "    \n",
    "    return epoch_metrics\n",
    "    \"\"\"\n",
    "    # Updates epoch metrics and prints them to file\n",
    "    epoch_metrics['train'].append([np.mean(acc)*100, np.mean(loss)])\n",
    "    met = '%s,%s,%s,' % (i+1, np.mean(acc)*100, np.mean(loss))\n",
    "    printO(met, filename=metrics_path, new_line=False)\n",
    "    printO('Training mean of accuracy and loss for this epoch: %s' % epoch_metrics['train'][-1])\n",
    "    \n",
    "    printO('\\n')\n",
    "    # Epoch metrics updated and output\n",
    "    epoch_metrics['validation'].append([np.mean(acc)*100, np.mean(loss)])\n",
    "    met = '%s,%s' % (np.mean(acc)*100, np.mean(loss))\n",
    "    printO(met, filename=metrics_path)\n",
    "    printO('Validation mean of accuracy and loss for this epoch: %s' % epoch_metrics['validation'][-1])\n",
    "        \"\"\"\n",
    "def completeEpoch(epoch_metrics, metrics_file, acc, allAcc, loss, incorrect_dict, incorrectPreds_file,\n",
    "                      epoch_tick, epochs, epoch, file_to_write, models_base):\n",
    "\n",
    "    loss = [0, 0]\n",
    "    \n",
    "    allAcc.append(np.mean(acc)*100)\n",
    "    s, outCSV = mostCommonIncorrectPred(incorrect_dict)\n",
    "    printO(outCSV, filename=incorrectPreds_file)\n",
    "    \n",
    "    if max(allAcc) == allAcc[-1]:\n",
    "        model_path = os.path.join(models_base, 'ResNet-Ethnicity_Acc-%.2f_.h5' % allAcc[-1])\n",
    "        log_path = os.path.join(models_base, 'OUTLOG_ResNet-Ethnicity_Acc-%.2f_.txt' % allAcc[-1])\n",
    "        printO('CLEARFILE', filename=log_path)\n",
    "        outStr = 'LOG INFO FOR ETHNICITY TRAINING BEST MODEL FOUND \\n\\nEPOCH: %s\\nACCURACY: %s\\nLOSS: %s' % (\n",
    "            epoch+1, allAcc[-1], np.mean(loss))\n",
    "        outStr += s\n",
    "        printO(outStr, filename=log_path)\n",
    "        \n",
    "        model.save(model_path)\n",
    "        \n",
    "    printO('Accuracy of epoch: %.2f' % (np.mean(acc)*100), filename=file_to_write)\n",
    "    printO('Time of epoch: %s' % (datetime.now()-epoch_tick), filename=file_to_write)\n",
    "    printO('As of %s, estimated time remaining for training/validation: %s' % (datetime.now(),\n",
    "                            (datetime.now()-epoch_tick)*(epochs-(epoch+1))),\n",
    "          filename=file_to_write)\n",
    "    epoch_tick = datetime.now()\n",
    "    \n",
    "    return allAcc, epoch_tick\n",
    "    \"\"\"\n",
    "    # Epoch accuracy and metrics information output if current model is best model\n",
    "    allAcc.append(np.mean(acc)*100)\n",
    "    s, outCSV = mostCommonIncorrectPred(incorrect_dict)\n",
    "    printO(outCSV, filename=incorrect_preds_path)\n",
    "    if max(allAcc) == allAcc[-1]:\n",
    "        model_path = os.path.join(base, 'ethnicityV2_acc_%.2f_.h5' % allAcc[-1])\n",
    "        log_path = os.path.join(base, 'OUTLOG_ethnicityV2_acc_%.2f.txt' % allAcc[-1])\n",
    "        printO('CLEARFILE', filename=log_path)\n",
    "        outStr = 'LOG INFO FOR ETHNICITY TRAINING BEST MODEL FOUND\\n\\nEPOCH: %s\\nACCURACY: %s\\nLOSS: %s' % (\n",
    "                            i+1, allAcc[-1], np.mean(loss))\n",
    "        outStr += s\n",
    "        printO(outStr, filename=log_path)\n",
    "\n",
    "        for _file in os.listdir('/'.join(model_path.split('/')[:-1])):\n",
    "            if 'ethnicityV2_acc' in _file:\n",
    "                os.remove(os.path.join(base, _file))\n",
    "\n",
    "        model.save(model_path)\n",
    "\n",
    "    printO('Accuracy of epoch: %.2f' % (np.mean(acc)*100))\n",
    "    printO('Time for epoch: %s' % (datetime.now()-epoch_tick))\n",
    "    printO('As of %s; estimated time remaining for training/validation: %s' % (datetime.now(), \n",
    "                                        (datetime.now()-epoch_tick)*(epochs-(i+1))))\n",
    "    epoch_tick = datetime.now()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model with depth of 8 and stack size of 6\n",
    "depth = 8\n",
    "stack_size=6\n",
    "\n",
    "model = resnet_create(input_shape=input_shape, depth=8, num_classes=len(classes))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr_schedule(0)), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "image_max=3200\n",
    "batch_size=128\n",
    "allAcc = []\n",
    "\n",
    "base_models = 'ResNetData/models'\n",
    "base_logs = 'ResNetData/logs'\n",
    "progress_log = os.path.join(base_logs, 'ResNet-printout.txt')\n",
    "metrics_path = os.path.join(base_logs, 'ResNet-ethModelMetrics.csv')\n",
    "incorrect_preds_path = os.path.join(base_logs, 'ResNet-incorrectPredMetrics.csv')\n",
    "\n",
    "printO('CLEARFILE', filename=progress_log)\n",
    "printO('CLEARFILE', filename=metrics_path, custom_header='EPOCH,TR_ACC,TR_LOSS,VAL_ACC,VAL_LOSS\\n')\n",
    "printO('CLEARFILE', filename=incorrect_preds_path, header=False)\n",
    "\n",
    "ticker = datetime.now()\n",
    "epoch_tick = datetime.now()\n",
    "epoch_metrics = {'train': [], 'validation': []} # Metrics list for loss and accuracy to be stored in\n",
    "\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        loss = [0, 0]\n",
    "        printO('\\n' + '='*30 + '\\n' + 'Epoch %s of %s' % (i+1, epochs) + '\\n' + '='*30 + '\\n', \n",
    "                           filename=progress_log)\n",
    "\n",
    "        c = 0\n",
    "        acc = []\n",
    "        temp_train = tr_set\n",
    "        while temp_train.shape[0] > 0:\n",
    "            temp_train, X_tr, Y_tr = getBatch(temp_train, image_max)\n",
    "            #temp_train, current_batch = getMaxBatch(temp_train, image_max)\n",
    "\n",
    "            #X_tr = load_images(current_batch['path'].tolist())\n",
    "            #Y_tr = current_batch['ethnicity'].tolist()\n",
    "\n",
    "            batchTime = datetime.now()\n",
    "            batches=0\n",
    "\n",
    "            for X_batch, Y_batch in imageGen.flow(X_tr, Y_tr, batch_size=batch_size):\n",
    "                model.fit(X_batch, Y_batch, verbose=0)\n",
    "                batches += 1\n",
    "                acc, incorrect_dict, batchTime = midTrainTest(model, X_batch, Y_batch, incorrect_dict, acc,\n",
    "                                                      batches, progress_log, batchTime, 'training')\n",
    "                if batches >= len(X_tr) / batch_size:\n",
    "                    break\n",
    "                elif batches % 10 == 0:\n",
    "                    acc, incorrect_dict, batchTime = midTrainTest(model, X_batch, Y_batch, incorrect_dict, acc,\n",
    "                                                      batches, progress_log, batchTime, 'training')\n",
    "\n",
    "            c, ticker = postBatchProcessing(c, tr_set, temp_train, image_max, ticker, progress_log)\n",
    "\n",
    "        epoch_metrics = updateEpochMetrics(epoch_metrics, metrics_path, acc, allAcc, loss, i, 'train', progress_log)\n",
    "\n",
    "        incorrect_dict = False\n",
    "        temp_val = val_set\n",
    "        ticker = datetime.now()\n",
    "        c = 0\n",
    "        acc = []\n",
    "        while temp_val.shape[0] > 0:\n",
    "            temp_val, X_val, Y_val = getBatch(temp_val, image_max)\n",
    "            #temp_validation, current_batch = getMaxBatch(temp_validation, image_max)\n",
    "\n",
    "            #X_val = load_images(current_batch['path'].tolist())\n",
    "            #Y_val = current_batch['ethnicity'].tolist()\n",
    "            batchTime = datetime.now()\n",
    "            batches = 0\n",
    "\n",
    "            for X_batch, Y_batch in imageGen.flow(X_val, Y_val, batch_size=batch_size):\n",
    "                a, incorrect_dict = getAcc(model, X_batch, Y_batch, incorrect_dict)\n",
    "                acc.append(a)\n",
    "                batches += 1\n",
    "\n",
    "                if batches >= len(X_val) / batch_size:\n",
    "                    break\n",
    "                elif batches % 10 == 0:\n",
    "                    acc, incorrect_dict, batchTime = midTrainTest(model, X_batch, Y_batch, incorrect_dict, acc,\n",
    "                                                      batches, progress_log, batchTime, 'training')\n",
    "\n",
    "            c, ticker = postBatchProcessing(c, val_set, temp_val, image_max, ticker, progress_log, 'validation')\n",
    "\n",
    "        epoch_metrics = updateEpochMetrics(epoch_metrics, metrics_path, acc, allAcc, loss, i, 'validation',\n",
    "                                          progress_log)\n",
    "\n",
    "        allAcc, epoch_tick = completeEpoch(epoch_metrics, metrics_path, acc, allAcc, loss, \n",
    "                        incorrect_dict, incorrect_preds_path, epoch_tick, epochs, i, progress_log,\n",
    "                                          base_models)\n",
    "            \n",
    "except Exception as e:\n",
    "    printO('MODEL TRAINING FAILURE\\n\\nERROR:\\n%s' % e, filename=progress_log)\n",
    "    \n",
    "\"\"\"\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True, callbacks=callbacks)\n",
    "\n",
    "pandas.DataFrame(history.history).to_csv(\"history.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
