{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ALWAYS COMMIT CUDA DEVICES EMPTY\n",
    "# Environment declarations for adding GPUs to process\n",
    "# If devices string is changed, must restart kernal to use new configuration\n",
    "os.environ[\"CUDA__DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from math import ceil\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Lambda, \\\n",
    "                                Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crops = 'images/cropped'\n",
    "\n",
    "# Gets all full paths for cropped images in images folder and video frame folder\n",
    "def join_image_paths(): # Try train/validate on smaller set (only image crops)\n",
    "    # Look into cropping images and rescaling so faces are most of 224x244\n",
    "    paths = [image_crops]\n",
    "    allPaths = []\n",
    "    \n",
    "    # Iter through roots, iter through files in a root then append paths list with full path\n",
    "    for onePath in paths:\n",
    "        p = os.listdir(onePath)\n",
    "        shuffle(p)\n",
    "        for oneFile in p:\n",
    "            allPaths.append(os.path.join(onePath, oneFile))\n",
    "            \n",
    "    # Return list of all full paths\n",
    "    return allPaths\n",
    "\n",
    "# Function to format all filenames in 'image' column to only have subject number\n",
    "# Useful when replacing image names and correlating image with full path\n",
    "def format_subs(DF):\n",
    "    DF['image'] = DF['image'].apply(lambda c: c.split('_')[0])\n",
    "    return DF\n",
    "\n",
    "# Function to replace image names in DF with full path to image\n",
    "def replace_image_names(paths, DF):\n",
    "    print('Replacing filenames with full paths')\n",
    "    new_df = pd.DataFrame(columns=('path', 'ethnicity'))\n",
    "    df = format_subs(DF)\n",
    "    \n",
    "    lastTime = datetime.now()\n",
    "    for i, onePath in enumerate(paths):\n",
    "        if not yuanjie_crops in onePath:\n",
    "            fileSub = '-'.join(onePath.split('/')[-1].split('-')[2:]).split('_')[0]\n",
    "        else:\n",
    "            fileSub = '.'.join(onePath.split('/')[-1].split('_')[:2])\n",
    "            \n",
    "        fileEth = df[df['image']==fileSub]['ethnicity'].iloc[0]\n",
    "        \n",
    "        new_df.loc[i] = [onePath, fileEth]\n",
    "        \n",
    "        if i%10000==0:\n",
    "            if i == 0:\n",
    "                step = 1\n",
    "            else:\n",
    "                step = 10000\n",
    "            print(i, 'of', len(paths))\n",
    "            print('Estimated time remaining:', (datetime.now()-lastTime)*((len(paths)-(i+1))/(step)))\n",
    "            lastTime = datetime.now()\n",
    "    \n",
    "    print('\\nEthnicity Counts...')\n",
    "    for oneLabel in poss_labels:\n",
    "        print('%s: %s' % (oneLabel, new_df[new_df['ethnicity'] == oneLabel].shape[0]))\n",
    "    print('\\n')\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "# Arr is list of labels\n",
    "# Key is sorted de-duplicated list of labels\n",
    "def getOneHot(arr, key):\n",
    "    print('Processing one-hot encoding...')\n",
    "    output = np.zeros((arr.shape[0], len(key)))\n",
    "    for i, elem in enumerate(arr):\n",
    "        output[i][key.index(elem)] = 1\n",
    "    return output\n",
    "\n",
    "def split_sets(DF):\n",
    "    train, validate, test = np.split(DF.sample(frac=1).reset_index(drop=True), [int(.6*len(DF)), int(.8*len(DF))])\n",
    "    train = train.reset_index(drop=True)\n",
    "    validate = validate.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    \n",
    "    train.to_csv(training_path, index=False)\n",
    "    validate.to_csv(validation_path, index=False)\n",
    "    test.to_csv(testing_path, index=False)\n",
    "    \n",
    "    DF.to_csv(labels_path, index=False)\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "def conv_oneHot(DF):\n",
    "    DF['ethnicity'] = DF['ethnicity'].apply(lambda c: np.fromstring(c.replace('[', '')\n",
    "                                                        .replace(']', '').replace(',', ''), sep=' '))\n",
    "    \n",
    "    return DF\n",
    "\n",
    "def str_to_oneHot(string):\n",
    "    string = string.replace('[', '').replace(']', '').replace(',', '')\n",
    "    out_list = np.fromstring(string, dtype=np.float, sep=',')\n",
    "    \n",
    "    return out_list\n",
    "\n",
    "def remove_some_eth(df, label, reduce):\n",
    "    df['ethnicity'] = df['ethnicity']\n",
    "    base = df[df['ethnicity'] != label].reset_index(drop=True)\n",
    "    eth_to_drop = df[df['ethnicity'] == label].reset_index(drop=True)\n",
    "    eth = eth_to_drop.iloc[:int(eth_to_drop.shape[0]*reduce)]\n",
    "    \n",
    "    new_df = pd.concat([base, eth]).sample(frac=1).reset_index(drop=True)\n",
    "    print('Ethnicity %s reduced... new counts...' % label)\n",
    "    for l in sorted(set(new_df['ethnicity'].tolist())):\n",
    "        print('%s: %s' % (l, new_df[new_df['ethnicity']==l].shape[0]))\n",
    "    return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets ethnicity data for cropped images and inits CSV output paths\n",
    "ethPath = 'subData/ethLabels.csv'\n",
    "ethData = pd.read_csv(ethPath, index_col=False)\n",
    "training_path = 'subData/train.csv'\n",
    "validation_path = 'subData/validation.csv'\n",
    "testing_path = 'subData/testing.csv'\n",
    "labels_path = 'subData/labels.csv'\n",
    "    \n",
    "poss_labels = sorted(set(ethData['ethnicity'].tolist()))\n",
    "cropPaths = join_image_paths()\n",
    "\n",
    "n = datetime.now()\n",
    "choice = 1\n",
    "if choice == 1:\n",
    "    print('Processing labels...')\n",
    "    # Resets data in output files by re-processing all data... Takes longer than choice 2\n",
    "    ethData = remove_some_eth(replace_image_names(cropPaths, ethData), label='Caucasian', reduce=0.6)\n",
    "    ethData['ethnicity'] = list(getOneHot(np.array(ethData['ethnicity'].tolist()), poss_labels))\n",
    "    training_set, validation_set, testing_set = split_sets(ethData)\n",
    "    print('Total time to complete:', datetime.now()-n)\n",
    "elif choice == 2:\n",
    "    print('Loading data from CSVs...')\n",
    "    training_set = conv_oneHot(pd.read_csv(training_path))\n",
    "    validation_set = conv_oneHot(pd.read_csv(validation_path))\n",
    "    testing_set = conv_oneHot(pd.read_csv(testing_path))\n",
    "    ethData = pd.read_csv(labels_path)\n",
    "    print('Total time to complete:', datetime.now()-n)\n",
    "else:\n",
    "    print('Invalid choice...')\n",
    "    \n",
    "print('\\nTraining, validation and testing sets loaded...')\n",
    "print('Sizes:\\nTraining: %s\\nValidation: %s\\nTesting: %s' % (training_set.shape[0], validation_set.shape[0],\n",
    "                                                            testing_set.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethData['ethnicity'] = ethData['ethnicity'].astype(str)\n",
    "for oneLabel in sorted(set(ethData['ethnicity'].values.tolist())):\n",
    "    l = []\n",
    "    for char in oneLabel:\n",
    "        try:\n",
    "            l.append(float(char))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    print('\\n', poss_labels[np.argmax(l)], 'label:', oneLabel)\n",
    "    print('Train set instances: ', training_set[training_set['ethnicity'].apply(lambda c: np.argmax(c))==np.argmax(l)].shape[0])\n",
    "    print('Validation set instances: ', validation_set[validation_set['ethnicity'].apply(lambda c: np.argmax(c))==np.argmax(l)].shape[0])\n",
    "    print('Test set instances: ', testing_set[testing_set['ethnicity'].apply(lambda c: np.argmax(c))==np.argmax(l)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc(model, X_set, Y_set, incorrect_dict):\n",
    "    preds = model.predict(X_set)\n",
    "    if not incorrect_dict:\n",
    "        incorrect_dict = {key: [] for key in poss_labels}\n",
    "        \n",
    "    correct = 0\n",
    "    for i, prediction in enumerate(preds):\n",
    "        if np.argmax(prediction) == np.argmax(Y_set[i]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            actu_eth = poss_labels[np.argmax(Y_set[i])]\n",
    "            pred_eth = poss_labels[np.argmax(prediction)]\n",
    "            incorrect_dict[actu_eth].append(pred_eth)\n",
    "            \n",
    "    return correct/len(preds), incorrect_dict\n",
    "\n",
    "def mostCommonIncorrectPred(incorrect_dict):\n",
    "    outStr = '\\n\\nActual Ethnicity: Most Common Misprediction\\n'\n",
    "    outCSV = 'ACT_LABEL,' + ','.join(poss_labels) + '\\n'\n",
    "    for key in poss_labels:\n",
    "        amount = []\n",
    "        outCSV += key + ','\n",
    "        for lookFor in poss_labels:\n",
    "            amount.append(incorrect_dict[key].count(lookFor))\n",
    "            outCSV += str(amount[-1]) + ','\n",
    "            \n",
    "        outCSV += '\\n'\n",
    "        outStr += '%s: %s\\n' % (key, poss_labels[np.argmax(amount)])\n",
    "        \n",
    "    return outStr, outCSV\n",
    "            \n",
    "\n",
    "def getMaxBatch(DF, max_set):\n",
    "    current_batch = pd.DataFrame(columns=(list(DF)))\n",
    "    DF = DF.reset_index(drop=True)\n",
    "    \n",
    "    for i, row in DF.iterrows():\n",
    "            \n",
    "        current_batch.loc[i] = row\n",
    "        \n",
    "        if int(i) == max_set-1:\n",
    "            break\n",
    "        \n",
    "    DF = DF.drop(DF.index[:i+1])\n",
    "    \n",
    "    return DF.reset_index(drop=True), current_batch.reset_index(drop=True)\n",
    "\n",
    "def load_images(image_paths):\n",
    "    size = 224\n",
    "    all_images = np.zeros((len(image_paths), size, size, 3))\n",
    "    for i, _path in enumerate(image_paths):\n",
    "        # Read the image\n",
    "        img = plt.imread(_path)\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img,(size,size))\n",
    "        # Normalize the image\n",
    "        img = np.divide(img,[255.,255., 255.])\n",
    "        # Set into X_tr\n",
    "        all_images[i] = img\n",
    "        \n",
    "    return all_images\n",
    "\n",
    "file = 'logs/printout.txt'\n",
    "if not os.path.exists('/'.join(file.split('/')[:-1])):\n",
    "    os.mkdir(file)\n",
    "def printO(string, filename=file, header=True, custom_header=False, new_line=True):\n",
    "    if string=='CLEARFILE':\n",
    "        f = open(filename, 'w')\n",
    "        if custom_header:\n",
    "            fill = custom_header\n",
    "        elif header:\n",
    "            fill = 'Training began at: %s\\n\\n' % datetime.now()\n",
    "        else:\n",
    "            fill = ''\n",
    "        f.write(fill)\n",
    "        f.close()\n",
    "        print('User Output File %s Cleared...' % filename.split('/')[-1])\n",
    "    else:\n",
    "        print(string)\n",
    "        f = open(filename, 'a')\n",
    "        if new_line:\n",
    "            string += '\\n'\n",
    "        f.write(string)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model ready for training...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 15,244,100\n",
      "Trainable params: 15,244,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model off of VGG16 skipping top fully connected layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add average pulling layer (test results and also allows for CAM output)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add fully connected layer after average pulling\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add softmax for predictions\n",
    "#predictions = Dense(len(poss_labels), activation='softmax')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "# Set inputs (default) and outputs (new softmax layer)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile with SGD Momentum, low learning rate and categorical... consider lowering momentum\n",
    "# Use model.evaluate (look up docs) for training loss, also think about increasing learning rate\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.0005, momentum=0.9), loss='categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy'])\n",
    "print('Base model ready for training...')\n",
    "model.summary()\n",
    "plot_model(model, to_file='VGG16_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "image_max = 3200\n",
    "batch_size = 32 # 3200 / 32 = 100\n",
    "allAcc = []\n",
    "\n",
    "log_base = 'logs'\n",
    "if not os.path.exists(log_base):\n",
    "    os.mkdir(log_base)\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "# Set base path names and clear files of contents\n",
    "base = 'models/ethnicity/'\n",
    "if not os.path.exists(base):\n",
    "    os.mkdir(base)\n",
    "    \n",
    "metrics_path = os.path.join(log_base, 'ethModelMetrics.csv')\n",
    "incorrect_preds_path = os.path.join(log_base, 'incorrectPredictionMetric.csv')\n",
    "\n",
    "printO('CLEARFILE')\n",
    "printO('CLEARFILE', filename=metrics_path, custom_header='EPOCH,TR_ACC,TR_LOSS,VAL_ACC,VAL_LOSS\\n')\n",
    "printO('CLEARFILE', filename=incorrect_preds_path, header=False)\n",
    "\n",
    "# Create tickers for time estimates\n",
    "ticker = datetime.now()\n",
    "epoch_tick = datetime.now()\n",
    "epoch_metrics = {'train': [], 'validation': []} # Metrics list for loss and accuracy to be stored in\n",
    "\n",
    "# Try-except loop for logging of any errors\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        # Print user output to file\n",
    "        printO('\\n' + '='*30)\n",
    "        printO('Epoch %s of %s' %(i+1, epochs))\n",
    "        printO('='*30 + '\\n')\n",
    "\n",
    "        # Reset temp training set which is continuously made smaller by getMaxBatch func\n",
    "        print('Training...')\n",
    "        temp_train = training_set\n",
    "\n",
    "        # Init counter and metric lists\n",
    "        c = 0\n",
    "        acc = []\n",
    "        loss = []\n",
    "        incorrect_dict = False\n",
    "        while temp_train.shape[0] > 0: # Init while loop to check if temp train set is greater than 0\n",
    "            # Take current batch out of temp train batch of amount image_max then return resulting batches\n",
    "            temp_train, current_batch = getMaxBatch(temp_train, image_max)\n",
    "\n",
    "            # User output, loads X batch images and gets Y preds from current batch\n",
    "            print('Loading current batch of %s images into memory...' % current_batch.shape[0])\n",
    "            X_train = load_images(current_batch['path'].tolist())\n",
    "            Y_train = current_batch['ethnicity'].tolist()\n",
    "\n",
    "            # Inits batch time estimator and batch counter\n",
    "            batchTime = datetime.now()\n",
    "            batches = 0\n",
    "\n",
    "            # Cycles through training X and Y sets in sizes of batch_size\n",
    "            for X_batch, Y_batch in imageGen.flow(X_train, Y_train, batch_size=batch_size):\n",
    "                # Fits current batch to model, increments model\n",
    "                model.fit(X_batch, Y_batch, verbose=0)\n",
    "                batches += 1\n",
    "                if batches >= len(X_train) / batch_size:\n",
    "                    # Break the generator before it breaks us\n",
    "                    # AKA, generator will do infinite loop if we don't break\n",
    "                    break\n",
    "\n",
    "                # Updates user and metric information... gives time estimate on train batch completion\n",
    "                elif batches % 10 == 0:\n",
    "                    a, incorrect_dict = getAcc(model, X_batch, Y_batch, incorrect_dict)\n",
    "                    acc.append(a)\n",
    "                    loss.append(model.evaluate(X_batch, Y_batch, verbose=0))\n",
    "                    printO(\"Training - Batch : %s\" % batches),\n",
    "                    printO(\"Training - of batch %s\" % (len(X_train) // batch_size))\n",
    "                    printO(\"Estimated time for training batch completion: %s\" % (((datetime.now()-batchTime)/10)*\n",
    "                                                                        ((len(X_train)//batch_size)-batches)))\n",
    "                    batchTime = datetime.now()\n",
    "\n",
    "            # Increments counter, more user output\n",
    "            c += 1\n",
    "            printO('Training - At iteration %s of %s for batches' % (c, ceil(training_set.shape[0]/image_max)))\n",
    "            printO('Estimated time for this epoch\\'s training completion: %s\\n' %((datetime.now()-ticker)*ceil(\n",
    "                                                                                temp_train.shape[0]/image_max)))\n",
    "            ticker = datetime.now()\n",
    "\n",
    "        # Updates epoch metrics and prints them to file\n",
    "        epoch_metrics['train'].append([np.mean(acc)*100, np.mean(loss)])\n",
    "        met = '%s,%s,%s,' % (i+1, np.mean(acc)*100, np.mean(loss))\n",
    "        printO(met, filename=metrics_path, new_line=False)\n",
    "        printO('Training mean of accuracy and loss for this epoch: %s' % epoch_metrics['train'][-1])\n",
    "\n",
    "        # Resets variables for validation stage\n",
    "        incorrect_dict = False\n",
    "        temp_validation = validation_set\n",
    "        ticker = datetime.now()\n",
    "        c = 0\n",
    "        acc = []\n",
    "        loss = []\n",
    "        print('Validating...')\n",
    "\n",
    "        while temp_validation.shape[0] > 0: # Init while loop to check if temp validation set is greater than 0\n",
    "            # Take current batch out of temp validatin batch of amount image_max then return resulting batches\n",
    "            temp_validation, current_batch = getMaxBatch(temp_validation, image_max)\n",
    "\n",
    "            # User output, loads X batch images and gets Y preds from current batch\n",
    "            X_validation = load_images(current_batch['path'].tolist())\n",
    "            Y_validation = current_batch['ethnicity'].tolist()\n",
    "            batchTime = datetime.now()\n",
    "            batches=0\n",
    "\n",
    "            # Cycles through training X and Y sets in sizes of batch_size\n",
    "            for X_batch, Y_batch in imageGen.flow(X_validation, Y_validation, batch_size=batch_size):\n",
    "                # Gets accuracy of validation set\n",
    "                a, incorrect_dict = getAcc(model, X_batch, Y_batch, incorrect_dict)\n",
    "                acc.append(a)\n",
    "                batches += 1\n",
    "\n",
    "                if batches >= len(X_validation) / batch_size:\n",
    "                    # Break the generator before it breaks us\n",
    "                    # AKA, generator will do infinite loop if we don't break\n",
    "                    break\n",
    "\n",
    "                # Ticker/user output\n",
    "                elif batches % 10 == 0:\n",
    "                    loss.append(model.evaluate(X_batch, Y_batch, verbose=0))\n",
    "                    printO(\"Validation - Batch : %s\" % batches),\n",
    "                    printO(\"Validation - of batch %s\" % (len(X_validation) // batch_size))\n",
    "                    printO(\"Estimated time for validation batch completion: %s\" % (((datetime.now()-batchTime)/10)*\n",
    "                                                                        ((len(X_validation)/batch_size)-batches)))\n",
    "                    batchTime = datetime.now()\n",
    "\n",
    "            c += 1\n",
    "            printO('Validation - At iteration %s of %s for batches' % (c, ceil(validation_set.shape[0]/image_max)))\n",
    "            printO('Estimated time for this epoch\\'s validation completion: %s\\n' %((datetime.now()-ticker)*ceil(\n",
    "                                                                                temp_validation.shape[0]/image_max)))\n",
    "            ticker = datetime.now()\n",
    "\n",
    "        printO('\\n')\n",
    "        # Epoch metrics updated and output\n",
    "        epoch_metrics['validation'].append([np.mean(acc)*100, np.mean(loss)])\n",
    "        met = '%s,%s' % (np.mean(acc)*100, np.mean(loss))\n",
    "        printO(met, filename=metrics_path)\n",
    "        printO('Validation mean of accuracy and loss for this epoch: %s' % epoch_metrics['validation'][-1])\n",
    "\n",
    "        # Epoch accuracy and metrics information output if current model is best model\n",
    "        allAcc.append(np.mean(acc)*100)\n",
    "        s, outCSV = mostCommonIncorrectPred(incorrect_dict)\n",
    "        printO(outCSV, filename=incorrect_preds_path)\n",
    "        if max(allAcc) == allAcc[-1]:\n",
    "            model_path = os.path.join(base, 'ethnicity_acc_%.2f_.h5' % allAcc[-1])\n",
    "            log_path = os.path.join(base, 'LOG-ethnicity_acc_%.2f.txt' % allAcc[-1])\n",
    "            printO('CLEARFILE', filename=log_path)\n",
    "            outStr = 'LOG INFO FOR ETHNICITY TRAINING BEST MODEL FOUND\\n\\nEPOCH: %s\\nACCURACY: %s\\nLOSS: %s' % (\n",
    "                                i+1, allAcc[-1], np.mean(loss))\n",
    "            outStr += s\n",
    "            printO(outStr, filename=log_path)\n",
    "\n",
    "            for _file in os.listdir('/'.join(model_path.split('/')[:-1])):\n",
    "                if 'ethnicity_acc' in _file:\n",
    "                    os.remove(os.path.join(base, _file))\n",
    "\n",
    "            model.save(model_path)\n",
    "\n",
    "        printO('Accuracy of epoch: %.2f' % (np.mean(acc)*100))\n",
    "        printO('Time for epoch: %s' % (datetime.now()-epoch_tick))\n",
    "        printO('As of %s; estimated time remaining for training/validation: %s' % (datetime.now(), \n",
    "                                            (datetime.now()-epoch_tick)*(epochs-(i+1))))\n",
    "        epoch_tick = datetime.now()\n",
    "        \n",
    "except Exception as e:\n",
    "    printO('MODEL TRAINING FAILURE\\n\\nERROR:\\n%s' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
